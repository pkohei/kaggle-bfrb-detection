#!/usr/bin/env python3
"""
å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå­¦ç¿’ã®ã‚¯ã‚¤ãƒƒã‚¯ç‰ˆï¼ˆçŸ­æ™‚é–“å®Ÿè¡Œï¼‰
"""

import time
import json
from pathlib import Path
from typing import Dict, Any, Tuple, List
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
import lightgbm as lgb


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå­¦ç¿’å®Ÿé¨“ï¼ˆã‚¯ã‚¤ãƒƒã‚¯ç‰ˆï¼‰")
    print("=" * 50)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ä¸­...")
    start_time = time.time()
    train_df = pd.read_parquet("data/train.parquet")
    test_df = pd.read_parquet("data/test.parquet")
    print(f"èª­ã¿è¾¼ã¿å®Œäº†: {time.time() - start_time:.2f}ç§’")
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape}")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df.shape}")
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã‚’ç‰¹å®š
    target_col = 'behavior'
    
    # æ•°å€¤ç‰¹å¾´é‡ã‚’é¸æŠ
    feature_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()
    if target_col in feature_cols:
        feature_cols.remove(target_col)
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
    X = train_df[feature_cols].values
    y = train_df[target_col].values
    X_test = test_df[feature_cols].values
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®æ•°å€¤åŒ–
    le = LabelEncoder()
    y = le.fit_transform(y)
    
    # æ¬ æå€¤å‡¦ç†
    X = np.nan_to_num(X, nan=0.0)
    X_test = np.nan_to_num(X_test, nan=0.0)
    
    print(f"\nç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    print(f"ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: {np.bincount(y)}")
    
    # è¨“ç·´ãƒ»æ¤œè¨¼åˆ†å‰²
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    results = []
    
    # RandomForestï¼ˆè»½é‡ç‰ˆï¼‰
    print("\n=== RandomForestè¨“ç·´ ===")
    start_time = time.time()
    rf_model = RandomForestClassifier(
        n_estimators=100,  # 200â†’100ã«å‰Šæ¸›
        max_depth=15,      # 20â†’15ã«å‰Šæ¸›
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)
    rf_train_time = time.time() - start_time
    
    rf_pred = rf_model.predict(X_val)
    rf_accuracy = accuracy_score(y_val, rf_pred)
    print(f"RandomForestç²¾åº¦: {rf_accuracy:.4f} (è¨“ç·´æ™‚é–“: {rf_train_time:.1f}ç§’)")
    
    # LightGBMï¼ˆè»½é‡ç‰ˆï¼‰
    print("\n=== LightGBMè¨“ç·´ ===")
    start_time = time.time()
    lgb_model = lgb.LGBMClassifier(
        objective='multiclass',
        num_class=len(np.unique(y)),
        n_estimators=100,  # 500â†’100ã«å‰Šæ¸›
        learning_rate=0.1,  # 0.05â†’0.1ã«å¢—åŠ 
        num_leaves=31,
        class_weight='balanced',
        random_state=42,
        verbose=-1
    )
    lgb_model.fit(X_train, y_train)
    lgb_train_time = time.time() - start_time
    
    lgb_pred = lgb_model.predict(X_val)
    lgb_accuracy = accuracy_score(y_val, lgb_pred)
    print(f"LightGBMç²¾åº¦: {lgb_accuracy:.4f} (è¨“ç·´æ™‚é–“: {lgb_train_time:.1f}ç§’)")
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    best_model = rf_model if rf_accuracy > lgb_accuracy else lgb_model
    best_name = "RandomForest" if rf_accuracy > lgb_accuracy else "LightGBM"
    best_accuracy = max(rf_accuracy, lgb_accuracy)
    
    predictions = best_model.predict(X_test)
    
    # å…ƒã®ãƒ©ãƒ™ãƒ«ã«æˆ»ã™
    predictions_labels = le.inverse_transform(predictions)
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    submission_df = pd.DataFrame({
        'id': range(len(predictions)),
        'behavior': predictions_labels
    })
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    submission_file = f"submissions/full_dataset_quick_{best_name.lower()}_{timestamp}.csv"
    submission_df.to_csv(submission_file, index=False)
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 50)
    print("ğŸ‰ å®Ÿé¨“å®Œäº†ã‚µãƒãƒªãƒ¼")
    print("=" * 50)
    print(f"RandomForestç²¾åº¦: {rf_accuracy:.4f}")
    print(f"LightGBMç²¾åº¦: {lgb_accuracy:.4f}")
    print(f"æœ€é«˜ç²¾åº¦: {best_name} ({best_accuracy:.4f})")
    print(f"æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: {submission_file}")
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
    baseline_accuracy = 0.7361
    improvement = best_accuracy - baseline_accuracy
    print(f"\nãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ:")
    print(f"  å‰å›: {baseline_accuracy:.4f}")
    print(f"  ä»Šå›: {best_accuracy:.4f}")
    print(f"  æ”¹å–„: {improvement:+.4f} ({improvement/baseline_accuracy*100:+.1f}%)")
    
    # çµæœã‚’ä¿å­˜
    results = {
        'experiment': 'full_dataset_quick',
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'baseline_accuracy': baseline_accuracy,
        'randomforest_accuracy': rf_accuracy,
        'lightgbm_accuracy': lgb_accuracy,
        'best_model': best_name,
        'best_accuracy': best_accuracy,
        'improvement': improvement,
        'improvement_percent': improvement/baseline_accuracy*100,
        'submission_file': submission_file
    }
    
    with open('results/full_dataset_quick_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ¨ å®Ÿé¨“å®Œäº†ï¼çµæœä¿å­˜: results/full_dataset_quick_results.json")


if __name__ == "__main__":
    main()